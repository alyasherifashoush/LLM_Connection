{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "56acc319",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "from outlines.models import openai "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b513342f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import outlines\n",
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "import asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "645f754d",
   "metadata": {},
   "outputs": [
    {
     "ename": "OpenAIError",
     "evalue": "The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mOpenAIError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[10]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Set up the OpenAI GPT-4 model\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m model = \u001b[43mopenai\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.13/functools.py:934\u001b[39m, in \u001b[36msingledispatch.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    931\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[32m    932\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires at least \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    933\u001b[39m                     \u001b[33m'\u001b[39m\u001b[33m1 positional argument\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m934\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mount/arbeitsdaten/studenten4/ashousaa/.env/lib64/python3.13/site-packages/outlines/models/openai.py:272\u001b[39m, in \u001b[36mopenai_model\u001b[39m\u001b[34m(model_name, config, **openai_client_params)\u001b[39m\n\u001b[32m    269\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    270\u001b[39m     config = OpenAIConfig(model=model_name)\n\u001b[32m--> \u001b[39m\u001b[32m272\u001b[39m client = \u001b[43mAsyncOpenAI\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mopenai_client_params\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m OpenAI(client, config)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mount/arbeitsdaten/studenten4/ashousaa/.env/lib64/python3.13/site-packages/openai/_client.py:349\u001b[39m, in \u001b[36mAsyncOpenAI.__init__\u001b[39m\u001b[34m(self, api_key, organization, project, base_url, websocket_base_url, timeout, max_retries, default_headers, default_query, http_client, _strict_response_validation)\u001b[39m\n\u001b[32m    347\u001b[39m     api_key = os.environ.get(\u001b[33m\"\u001b[39m\u001b[33mOPENAI_API_KEY\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    348\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m api_key \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m349\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m OpenAIError(\n\u001b[32m    350\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mThe api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    351\u001b[39m     )\n\u001b[32m    352\u001b[39m \u001b[38;5;28mself\u001b[39m.api_key = api_key\n\u001b[32m    354\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m organization \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[31mOpenAIError\u001b[39m: The api_key client option must be set either by passing api_key to the client or by setting the OPENAI_API_KEY environment variable"
     ]
    }
   ],
   "source": [
    "# Set up the OpenAI GPT-4 model\n",
    "model = openai(\"gpt-4\", api_key=\"your-actual-openai-api-key\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6cc3e32f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define a schema with 1–5 scores\n",
    "class LanguageQualityScore(BaseModel):\n",
    "    clarity: Literal[1, 2, 3, 4, 5]\n",
    "    conciseness: Literal[1, 2, 3, 4, 5]\n",
    "    coherence: Literal[1, 2, 3, 4, 5]\n",
    "    total_score: float  # will be average of the above\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a71763",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'tokenizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Load the model (Outlines will use OpenAI by default)\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m generator = \u001b[43moutlines\u001b[49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjson\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mgpt-4\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mLanguageQualityScore\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# can be changed to whatever model you want\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.13/functools.py:934\u001b[39m, in \u001b[36msingledispatch.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    931\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[32m    932\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires at least \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    933\u001b[39m                     \u001b[33m'\u001b[39m\u001b[33m1 positional argument\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m934\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mount/arbeitsdaten/studenten4/ashousaa/.env/lib64/python3.13/site-packages/outlines/generate/json.py:52\u001b[39m, in \u001b[36mjson\u001b[39m\u001b[34m(model, schema_object, sampler, whitespace_pattern)\u001b[39m\n\u001b[32m     50\u001b[39m     schema = pyjson.dumps(schema_object.model_json_schema())\n\u001b[32m     51\u001b[39m     regex_str = build_regex_from_schema(schema, whitespace_pattern)\n\u001b[32m---> \u001b[39m\u001b[32m52\u001b[39m     generator = \u001b[43mregex\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mregex_str\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msampler\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     53\u001b[39m     generator.format_sequence = \u001b[38;5;28;01mlambda\u001b[39;00m x: schema_object.parse_raw(x)\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(schema_object, \u001b[38;5;28mtype\u001b[39m(Enum)):\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/usr/lib64/python3.13/functools.py:934\u001b[39m, in \u001b[36msingledispatch.<locals>.wrapper\u001b[39m\u001b[34m(*args, **kw)\u001b[39m\n\u001b[32m    931\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m args:\n\u001b[32m    932\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mfuncname\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m requires at least \u001b[39m\u001b[33m'\u001b[39m\n\u001b[32m    933\u001b[39m                     \u001b[33m'\u001b[39m\u001b[33m1 positional argument\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m934\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdispatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[34;43m__class__\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkw\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m/mount/arbeitsdaten/studenten4/ashousaa/.env/lib64/python3.13/site-packages/outlines/generate/regex.py:34\u001b[39m, in \u001b[36mregex\u001b[39m\u001b[34m(model, regex_str, sampler)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"Generate structured text in the language of a regular expression.\u001b[39;00m\n\u001b[32m     14\u001b[39m \n\u001b[32m     15\u001b[39m \u001b[33;03mParameters\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     30\u001b[39m \n\u001b[32m     31\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01moutlines\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mprocessors\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m RegexLogitsProcessor\n\u001b[32m---> \u001b[39m\u001b[32m34\u001b[39m logits_processor = RegexLogitsProcessor(regex_str, tokenizer=\u001b[43mmodel\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtokenizer\u001b[49m)\n\u001b[32m     35\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m SequenceGeneratorAdapter(model, logits_processor, sampler)\n",
      "\u001b[31mAttributeError\u001b[39m: 'str' object has no attribute 'tokenizer'"
     ]
    }
   ],
   "source": [
    "# Load the model (Outlines will use OpenAI by default)\n",
    "generator = outlines.generate.json(model, LanguageQualityScore) # can be changed to whatever model you want"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b33049c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_prompt(response: str) -> str:\n",
    "    return f\"\"\"\n",
    "You are a language quality evaluator. Given the following RESPONSE, rate it on the following criteria using a 1–5 Likert scale:\n",
    "\n",
    "- Clarity: How understandable is the response?\n",
    "- Conciseness: How free is the response from unnecessary repetition or detail?\n",
    "- Coherence: How logically does the response flow?\n",
    "\n",
    "Use this 1–5 Likert scale:\n",
    "1 - Very Poor\n",
    "2 - Poor\n",
    "3 - Fair\n",
    "4 - Good\n",
    "5 - Excellent\n",
    "\n",
    "Then, compute total_score as the average of the three ratings, rounded to one decimal place.\n",
    "\n",
    "Respond strictly in this format:\n",
    "{{\n",
    "  \"clarity\": <1–5>,\n",
    "  \"clarity_reason\": \"<short justification>\",\n",
    "  \"conciseness\": <1–5>,\n",
    "  \"conciseness_reason\": \"<short justification>\",\n",
    "  \"coherence\": <1–5>,\n",
    "  \"coherence_reason\": \"<short justification>\",\n",
    "  \"total_score\": <float>\n",
    "}}\n",
    "\n",
    "RESPONSE:\n",
    "\\\"\\\"\\\"\n",
    "{response}\n",
    "\\\"\\\"\\\"\n",
    "\"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b224bf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_response(response):\n",
    "    prompt = build_prompt(response)\n",
    "    try:\n",
    "        result = generator(prompt)\n",
    "        print(result)\n",
    "        \n",
    "    except ValidationError as e:\n",
    "        print(\"Invalid output:\", e)\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5bbc906",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Example response to evaluate\n",
    "    example_response = \"\"\"\n",
    "    An official trip, in the context of this specific legal document we're currently examining, can be understood as instances of movement away from the typical location where one performs their professional duties. These movements are undertaken for the purpose of engaging in tasks related to one's official responsibilities. However, the initiation of these journeys hinges upon the explicit directive or agreement from a supervisory figure who holds the relevant authority, except in certain situations where such a directive or agreement is deemed unnecessary due to either the inherent characteristics of the role held by the individual undertaking the journey or the intrinsic nature of the tasks to be performed during this period of movement\n",
    "    \"\"\"\n",
    "    \n",
    "    # Evaluate the example response\n",
    "    evaluate_response(example_response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
