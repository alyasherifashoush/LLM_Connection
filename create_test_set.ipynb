{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "dce50f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set saved to: final_test_set.csv\n"
     ]
    }
   ],
   "source": [
    "# import re\n",
    "# import csv\n",
    "# from docx import Document\n",
    "# from collections import defaultdict\n",
    "\n",
    "# # === Step 1: Load and parse the DOCX file ===\n",
    "# def parse_docx(docx_path):\n",
    "#     doc = Document(docx_path)\n",
    "#     qa_data = [] # List to hold question-answer-chunks dictionaries\n",
    "#     buffer = \"\"  # Buffer to accumulate text for answers\n",
    "#     for para in doc.paragraphs:\n",
    "#         text = para.text.strip() # Remove leading/trailing whitespace\n",
    "#         if not text:\n",
    "#             continue\n",
    "#         if re.match(r\"^\\d{0,2}\\)?\\s?[\\w\\s,?'\\\"]+:?$\", text) or text.endswith(\"?\"):# Check if it's a question\n",
    "#             if buffer:\n",
    "#                 qa_data[-1][\"answer\"] += \" \" + buffer.strip() # Since a new question is found, append the content of the buffer to the last answer\n",
    "#                 buffer = \"\" # Reset buffer\n",
    "#             qa_data.append({\"question\": text, \"answer\": \"\", \"chunk\": \"\"}) #Initialize a new entry and append it to the list\n",
    "#         elif text.lower().startswith(\"chunk_\"): # Check if it's a chunk\n",
    "#             if qa_data: # If there's an active question otherwise skip\n",
    "#                 qa_data[-1][\"chunk\"] = text #Adds the chunk number to the most recently added question in the qa_data list.\n",
    "#         else:\n",
    "#             buffer += \" \" + text # Accumulate text for answers\n",
    "#     if buffer and qa_data:\n",
    "#         qa_data[-1][\"answer\"] += \" \" + buffer.strip() # Append any remaining text in the buffer to the last answer\n",
    "\n",
    "#     # Extract chunk from answer if embedded\n",
    "#     for entry in qa_data:\n",
    "#         match = re.search(r\"(chunk_\\d+)\", entry[\"answer\"], re.IGNORECASE) # Check if the answer contains a chunk reference\n",
    "#         if match:\n",
    "#             entry[\"chunk\"] = match.group(1) # Extract the chunk number\n",
    "#             entry[\"answer\"] = re.sub(r\"\\s*chunk_\\d+\", \"\", entry[\"answer\"], flags=re.IGNORECASE).strip() # Remove the chunk reference from the answer\n",
    "#     return qa_data # Return the list of dictionaries containing question, answer, and chunk\n",
    "\n",
    "# # === Step 2: Parse the paraphrased questions ===\n",
    "# def parse_paraphrases(txt_path):\n",
    "#     paraphrased_map = defaultdict(list)# Initialize a default dictionary to hold paraphrased questions. A defaultdict is a dictionary that returns a default value when a key is not found.\n",
    "#     current_qid = None # Variable to keep track of the current question ID\n",
    "#     with open(txt_path, \"r\", encoding=\"utf-8\") as file:\n",
    "#         for line in file:\n",
    "#             line = line.strip() # Remove leading/trailing whitespace\n",
    "#             if not line:\n",
    "#                 continue\n",
    "#             match = re.match(r\"Q(\\d+)\\s+Paraphrased: *(.*)\", line) # Check if the line starts with a question ID and paraphrased text\n",
    "#             if match:\n",
    "#                 current_qid = int(match.group(1)) # The first pattern grabber (\\d+) picks up the numbers after 'Q'. This is the first captured group\n",
    "#                 paraphrased = match.group(2).strip(\" :\") # The second grabber (.*) picks up all the words after 'Paraphrased:'. This is the second captured group.\n",
    "#                 if paraphrased:  \n",
    "#                     paraphrased_map[current_qid].append(paraphrased) # Add the paraphrased question to the list for the current question ID\n",
    "#             elif current_qid is not None and line.startswith(\"*\"):# Check if the line starts with an asterisk, indicating a paraphrased question\n",
    "#                 paraphrased_map[current_qid].append(line.strip(\"* \").strip())\n",
    "#             elif current_qid is not None:\n",
    "#                 paraphrased_map[current_qid].append(line.strip()) #If we have a current_qid and the line didn't start with \"Q...\" or an asterisk, we assume this line is also a paraphrase for the current original question.\n",
    "#     return paraphrased_map\n",
    "\n",
    "# # === Step 3: Create the test set and write to CSV ===\n",
    "# def create_test_set_csv(qa_data, paraphrased_map, csv_path):\n",
    "#     with open(csv_path, mode=\"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "#         writer = csv.writer(f) # Create a CSV writer object\n",
    "#         writer.writerow([\"Number\", \"Question\", \"Answer\", \"Chunk\"])# Write the header row\n",
    "\n",
    "#         for i, qa in enumerate(qa_data[:75]):#Loop through the first 75 entries in the qa_data list\n",
    "#             writer.writerow([2*i+1, qa[\"question\"], qa[\"answer\"], qa[\"chunk\"]]) # Write the original question, answer, and chunk\n",
    "#             para_qs = paraphrased_map.get(i+1) # Get the paraphrased questions for the current question ID. The i+1 is used because the question IDs in the paraphrased_map are 1-based.\n",
    "#             if para_qs:\n",
    "#                 writer.writerow([2*i+2, para_qs[0], qa[\"answer\"], qa[\"chunk\"]]) # Write the first paraphrased question, answer, and chunk\n",
    "#     print(f\"Test set saved to: {csv_path}\")\n",
    "\n",
    "# # === Main function ===\n",
    "# def main():\n",
    "#     docx_path = \"Manual QA.docx\"\n",
    "#     txt_path = \"paraphrase_adjusted.txt\"\n",
    "#     output_csv = \"final_test_set.csv\"\n",
    "\n",
    "#     qa_data = parse_docx(docx_path)\n",
    "#     paraphrased_map = parse_paraphrases(txt_path)\n",
    "#     create_test_set_csv(qa_data, paraphrased_map, output_csv)\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "\n",
    "\n",
    "# def load_data_from_docs():\n",
    "#     \"\"\"Loads data from the documents and returns dictionaries.\"\"\"\n",
    "    \n",
    "#     import docx\n",
    "#     doc = docx.Document(\"Manual QA.docx\")\n",
    "#     questions = []\n",
    "#     answers = []\n",
    "#     chunks = []\n",
    "\n",
    "#     for paragraph in doc.paragraphs:\n",
    "#         if paragraph.text.strip() != \"\":\n",
    "#             if paragraph.text.strip().startswith(\"What\") or paragraph.text.strip().startswith(\"Is \") or paragraph.text.strip().startswith(\"Will\") or paragraph.text.strip().startswith(\"Can\") or paragraph.text.strip().startswith(\"When\")  or paragraph.text.strip().startswith(\"Are\") or paragraph.text.strip().startswith(\"How\") or paragraph.text.strip().startswith(\"If\"):\n",
    "#               questions.append(paragraph.text.strip())\n",
    "#             elif paragraph.text.strip().startswith(\"Chunk_\"):\n",
    "#               chunks.append(paragraph.text.strip())\n",
    "#             else:\n",
    "#               answers.append(paragraph.text.strip())\n",
    "\n",
    "#     qa_data = []\n",
    "#     chunk_index = 0\n",
    "\n",
    "#     # If there are fewer chunks than questions, reuse the last chunk for all extra questions\n",
    "#     for i in range(len(questions)):\n",
    "#         # Ensure chunk index does not exceed the number of available chunks\n",
    "#         chunk = chunks[min(chunk_index, len(chunks) - 1)]  \n",
    "#         qa_data.append({\n",
    "#             \"question\": questions[i],\n",
    "#             \"answer\": answers[i],\n",
    "#             \"chunk\": chunk\n",
    "#         })\n",
    "#         if chunk_index < len(chunks) - 1:\n",
    "#             chunk_index += 1\n",
    "\n",
    "#     # Extract data from paraphrase_adjusted.txt\n",
    "#     with open(\"paraphrase_adjusted.txt\", \"r\") as file:\n",
    "#         paraphrase_text = file.readlines()\n",
    "\n",
    "#     paraphrased_questions = []\n",
    "#     for line in paraphrase_text:\n",
    "#         if line.strip() != \"\":\n",
    "#             match = re.search(r'Q\\d+ Paraphrased: (.*)', line)\n",
    "#             if match:\n",
    "#                 paraphrased_questions.append(match.group(1).strip())\n",
    "\n",
    "#     return qa_data, paraphrased_questions\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# import re\n",
    "# import csv\n",
    "# from docx import Document\n",
    "# from collections import defaultdict\n",
    "\n",
    "# # === Step 1: Load and parse the DOCX file ===\n",
    "# def parse_docx(docx_path):\n",
    "#     doc = Document(docx_path)\n",
    "#     qa_data = []  # List to hold question-answer-chunks dictionaries\n",
    "#     buffer = \"\"  # Buffer to accumulate text for answers\n",
    "#     for para in doc.paragraphs:\n",
    "#         text = para.text.strip()  # Remove leading/trailing whitespace\n",
    "#         if not text:\n",
    "#             continue\n",
    "#         if re.match(r\"^\\d{0,2}\\)?\\s?[\\w\\s,?'\\\"]+:?$\", text) or text.endswith(\"?\"):  # Check if it's a question\n",
    "#             if buffer:\n",
    "#                 qa_data[-1][\"answer\"] += \" \" + buffer.strip()  # Append the content of the buffer to the last answer\n",
    "#                 buffer = \"\"  # Reset buffer\n",
    "#             qa_data.append({\"question\": text, \"answer\": \"\", \"chunk\": \"\"})  # Initialize a new entry\n",
    "#         elif text.lower().startswith(\"chunk_\"):  # Check if it's a chunk\n",
    "#             if qa_data:  # If there's an active question\n",
    "#                 qa_data[-1][\"chunk\"] = text  # Add the chunk number to the most recent question\n",
    "#         else:\n",
    "#             buffer += \" \" + text  # Accumulate text for answers\n",
    "#     if buffer and qa_data:\n",
    "#         qa_data[-1][\"answer\"] += \" \" + buffer.strip()  # Append any remaining text in the buffer\n",
    "\n",
    "#     # Extract chunk from answer if embedded\n",
    "#     for entry in qa_data:\n",
    "#         match = re.search(r\"(chunk_\\d+)\", entry[\"answer\"], re.IGNORECASE)  # Check if answer contains chunk reference\n",
    "#         if match:\n",
    "#             entry[\"chunk\"] = match.group(1)  # Extract chunk number\n",
    "#             entry[\"answer\"] = re.sub(r\"\\s*chunk_\\d+\", \"\", entry[\"answer\"], flags=re.IGNORECASE).strip()  # Remove chunk reference from answer\n",
    "#     return qa_data  # Return the list of dictionaries containing question, answer, and chunk\n",
    "\n",
    "# # === Step 2: Parse the paraphrased questions ===\n",
    "# def parse_paraphrases(txt_path):\n",
    "#     paraphrased_map = defaultdict(list)  # Initialize a default dictionary to hold paraphrased questions\n",
    "#     current_qid = None  # Variable to keep track of the current question ID\n",
    "#     with open(txt_path, \"r\", encoding=\"utf-8\") as file:\n",
    "#         for line in file:\n",
    "#             line = line.strip()  # Remove leading/trailing whitespace\n",
    "#             if not line:\n",
    "#                 continue\n",
    "#             match = re.match(r\"Q(\\d+)\\s+Paraphrased: *(.*)\", line)  # Check if the line starts with a question ID and paraphrased text\n",
    "#             if match:\n",
    "#                 current_qid = int(match.group(1))  # Get question ID\n",
    "#                 paraphrased = match.group(2).strip(\" :\")  # Get the paraphrased question text\n",
    "#                 if paraphrased:  \n",
    "#                     paraphrased_map[current_qid].append(paraphrased)  # Add paraphrased question\n",
    "#             elif current_qid is not None and line.startswith(\"*\"):  # If the line starts with an asterisk, it's a paraphrase\n",
    "#                 paraphrased_map[current_qid].append(line.strip(\"* \").strip())  # Add the paraphrase\n",
    "#             elif current_qid is not None:  # Otherwise, treat as a paraphrase\n",
    "#                 paraphrased_map[current_qid].append(line.strip())  # Add the paraphrase\n",
    "#     return paraphrased_map\n",
    "\n",
    "# # === Step 3: Create the test set and write to CSV ===\n",
    "# def create_test_set_csv(qa_data, paraphrased_map, csv_path):\n",
    "#     with open(csv_path, mode=\"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "#         writer = csv.writer(f)  # Create a CSV writer object\n",
    "#         writer.writerow([\"Number\", \"Question\", \"Answer\", \"Chunk\"])  # Write the header row\n",
    "\n",
    "#         question_number = 1  # Initialize question number\n",
    "\n",
    "#         # Loop through the qa_data to add questions\n",
    "#         for i, qa in enumerate(qa_data[:75]):  # Loop through the first 75 entries in the qa_data list\n",
    "#             # Write the original question with a unique number\n",
    "#             writer.writerow([question_number, qa[\"question\"], qa[\"answer\"], qa[\"chunk\"]])  \n",
    "#             question_number += 1  # Increment question number\n",
    "\n",
    "#             para_qs = paraphrased_map.get(i + 1)  # Get paraphrased questions for the current question ID\n",
    "#             if para_qs:\n",
    "#                 for paraphrase in para_qs:  # Loop through all paraphrases\n",
    "#                     writer.writerow([question_number, paraphrase, qa[\"answer\"], qa[\"chunk\"]])  # Write each paraphrase with a new unique number\n",
    "#                     question_number += 1  # Increment question number\n",
    "\n",
    "#     print(f\"Test set saved to: {csv_path}\")\n",
    "\n",
    "# # === Main function ===\n",
    "# def main():\n",
    "#     docx_path = \"Manual QA.docx\"\n",
    "#     txt_path = \"paraphrase_adjusted.txt\"\n",
    "#     output_csv = \"final_test_set.csv\"\n",
    "\n",
    "#     qa_data = parse_docx(docx_path)  # Parse the DOCX file\n",
    "#     paraphrased_map = parse_paraphrases(txt_path)  # Parse the paraphrased questions\n",
    "#     create_test_set_csv(qa_data, paraphrased_map, output_csv)  # Create the CSV file\n",
    "\n",
    "# if __name__ == \"__main__\":\n",
    "#     main()\n",
    "\n",
    "import re\n",
    "import csv\n",
    "from docx import Document\n",
    "from collections import defaultdict\n",
    "\n",
    "# === Step 1: Load and parse the DOCX file ===\n",
    "import re\n",
    "import csv\n",
    "\n",
    "from docx import Document\n",
    "from collections import defaultdict\n",
    "\n",
    "# === Step 1: Load and parse the DOCX file ===\n",
    "def parse_docx(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    qa_data = []  # List to hold question-answer-chunks dictionaries\n",
    "    buffer = \"\"  # Buffer to accumulate text for answers\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip()  # Remove leading/trailing whitespace\n",
    "        if not text:\n",
    "            continue\n",
    "        if re.match(r\"^\\d{0,2}\\)?\\s?[\\w\\s,?'\\\"]+:?$\", text) or text.endswith(\"?\"):  # Check if it's a question\n",
    "            if buffer:\n",
    "                qa_data[-1][\"answer\"] += \" \" + buffer.strip()  # Append the content of the buffer to the last answer\n",
    "                buffer = \"\"  # Reset buffer\n",
    "            qa_data.append({\"question\": text, \"answer\": \"\", \"chunk\": \"\"})  # Initialize a new entry\n",
    "        elif text.lower().startswith(\"chunk_\"):  # Check if it's a chunk\n",
    "            if qa_data:  # If there's an active question\n",
    "                qa_data[-1][\"chunk\"] = text  # Add the chunk number to the most recent question\n",
    "        else:\n",
    "            buffer += \" \" + text  # Accumulate text for answers\n",
    "    if buffer and qa_data:\n",
    "        qa_data[-1][\"answer\"] += \" \" + buffer.strip()  # Append any remaining text in the buffer\n",
    "\n",
    "    # Extract chunk from answer if embedded\n",
    "    for entry in qa_data:\n",
    "        match = re.search(r\"(chunk_\\d+)\", entry[\"answer\"], re.IGNORECASE)  # Check if answer contains chunk reference\n",
    "        if match:\n",
    "            entry[\"chunk\"] = match.group(1)  # Extract chunk number\n",
    "            entry[\"answer\"] = re.sub(r\"\\s*chunk_\\d+\", \"\", entry[\"answer\"], flags=re.IGNORECASE).strip()  # Remove chunk reference from answer\n",
    "    return qa_data  # Return the list of dictionaries containing question, answer, and chunk\n",
    "\n",
    "# === Step 2: Parse the paraphrased questions ===\n",
    "def parse_paraphrases(txt_path):\n",
    "    paraphrased_map = defaultdict(list)  # Initialize a default dictionary to hold paraphrased questions\n",
    "    current_qid = None  # Variable to keep track of the current question ID\n",
    "    with open(txt_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            line = line.strip()  # Remove leading/trailing whitespace\n",
    "            if not line:\n",
    "                continue\n",
    "            match = re.match(r\"Q(\\d+)\\s+Paraphrased: *(.*)\", line)  # Check if the line starts with a question ID and paraphrased text\n",
    "            if match:\n",
    "                current_qid = int(match.group(1))  # Get question ID\n",
    "                paraphrased = match.group(2).strip(\" :\")  # Get the paraphrased question text\n",
    "                if paraphrased:  \n",
    "                    paraphrased_map[current_qid].append(paraphrased)  # Add paraphrased question\n",
    "            elif current_qid is not None and line.startswith(\"*\"):  # If the line starts with an asterisk, it's a paraphrase\n",
    "                paraphrased_map[current_qid].append(line.strip(\"* \").strip())  # Add the paraphrase\n",
    "            elif current_qid is not None:  # Otherwise, treat as a paraphrase\n",
    "                paraphrased_map[current_qid].append(line.strip())  # Add the paraphrase\n",
    "    return paraphrased_map\n",
    "\n",
    "# === Step 3: Create the test set and write to CSV ===\n",
    "def create_test_set_csv(qa_data, paraphrased_map, csv_path):\n",
    "    with open(csv_path, mode=\"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.writer(f)  # Create a CSV writer object\n",
    "        writer.writerow([\"Number\", \"Question\", \"Answer\", \"Chunk\", \"Type\", \"Source_QID\"])  # Write the header row\n",
    "\n",
    "        question_number = 1  # Initialize question number\n",
    "\n",
    "        # Loop through the qa_data to add questions\n",
    "        for i, qa in enumerate(qa_data[:75]):  # Loop through the first 75 entries in the qa_data list\n",
    "            # Write the original question with a unique number and \"Original\" type\n",
    "            writer.writerow([question_number, qa[\"question\"], qa[\"answer\"], qa[\"chunk\"], \"Original\", \"\"])  \n",
    "            question_number += 1  # Increment question number\n",
    "\n",
    "            para_qs = paraphrased_map.get(i + 1)  # Get paraphrased questions for the current question ID\n",
    "            if para_qs:\n",
    "                for paraphrase in para_qs:  # Loop through all paraphrases\n",
    "                    # **Write each paraphrase with a new unique number and indicate from which question it was paraphrased**\n",
    "                    writer.writerow([question_number, paraphrase, qa[\"answer\"], qa[\"chunk\"], \"Paraphrased\", f\"Paraphrased from Ques_{i + 1} in Manual QA doc\"])  \n",
    "                    question_number += 1  # Increment question number\n",
    "\n",
    "    print(f\"Test set saved to: {csv_path}\")\n",
    "\n",
    "# === Main function ===\n",
    "def main():\n",
    "    docx_path = \"Manual QA.docx\"\n",
    "    txt_path = \"paraphrase_adjusted.txt\"\n",
    "    output_csv = \"final_test_set.csv\"\n",
    "\n",
    "    qa_data = parse_docx(docx_path)  # Parse the DOCX file\n",
    "    paraphrased_map = parse_paraphrases(txt_path)  # Parse the paraphrased questions\n",
    "    create_test_set_csv(qa_data, paraphrased_map, output_csv)  # Create the CSV file\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
