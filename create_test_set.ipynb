{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce50f62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set saved to: final_test_set.csv\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import csv\n",
    "from docx import Document\n",
    "from collections import defaultdict\n",
    "\n",
    "# === Step 1: Load and parse the DOCX file ===\n",
    "def parse_docx(docx_path):\n",
    "    doc = Document(docx_path)\n",
    "    qa_data = [] # List to hold question-answer-chunks dictionaries\n",
    "    buffer = \"\"  # Buffer to accumulate text for answers\n",
    "    for para in doc.paragraphs:\n",
    "        text = para.text.strip() # Remove leading/trailing whitespace\n",
    "        if not text:\n",
    "            continue\n",
    "        if re.match(r\"^\\d{0,2}\\)?\\s?[\\w\\s,?'\\\"]+:?$\", text) or text.endswith(\"?\"):# Check if it's a question\n",
    "            if buffer:\n",
    "                qa_data[-1][\"answer\"] += \" \" + buffer.strip() # Since a new question is found, append the content of the buffer to the last answer\n",
    "                buffer = \"\" # Reset buffer\n",
    "            qa_data.append({\"question\": text, \"answer\": \"\", \"chunk\": \"\"}) #Initialize a new entry and append it to the list\n",
    "        elif text.lower().startswith(\"chunk_\"): # Check if it's a chunk\n",
    "            if qa_data: # If there's an active question otherwise skip\n",
    "                qa_data[-1][\"chunk\"] = text #Adds the chunk number to the most recently added question in the qa_data list.\n",
    "        else:\n",
    "            buffer += \" \" + text # Accumulate text for answers\n",
    "    if buffer and qa_data:\n",
    "        qa_data[-1][\"answer\"] += \" \" + buffer.strip() # Append any remaining text in the buffer to the last answer\n",
    "\n",
    "    # Extract chunk from answer if embedded\n",
    "    for entry in qa_data:\n",
    "        match = re.search(r\"(chunk_\\d+)\", entry[\"answer\"], re.IGNORECASE) # Check if the answer contains a chunk reference\n",
    "        if match:\n",
    "            entry[\"chunk\"] = match.group(1) # Extract the chunk number\n",
    "            entry[\"answer\"] = re.sub(r\"\\s*chunk_\\d+\", \"\", entry[\"answer\"], flags=re.IGNORECASE).strip() # Remove the chunk reference from the answer\n",
    "    return qa_data # Return the list of dictionaries containing question, answer, and chunk\n",
    "\n",
    "# === Step 2: Parse the paraphrased questions ===\n",
    "def parse_paraphrases(txt_path):\n",
    "    paraphrased_map = defaultdict(list)# Initialize a default dictionary to hold paraphrased questions. A defaultdict is a dictionary that returns a default value when a key is not found.\n",
    "    current_qid = None # Variable to keep track of the current question ID\n",
    "    with open(txt_path, \"r\", encoding=\"utf-8\") as file:\n",
    "        for line in file:\n",
    "            line = line.strip() # Remove leading/trailing whitespace\n",
    "            if not line:\n",
    "                continue\n",
    "            match = re.match(r\"Q(\\d+)\\s+Paraphrased: *(.*)\", line) # Check if the line starts with a question ID and paraphrased text\n",
    "            if match:\n",
    "                current_qid = int(match.group(1)) # The first pattern grabber (\\d+) picks up the numbers after 'Q'. This is the first captured group\n",
    "                paraphrased = match.group(2).strip(\" :\") # The second grabber (.*) picks up all the words after 'Paraphrased:'. This is the second captured group.\n",
    "                if paraphrased:  \n",
    "                    paraphrased_map[current_qid].append(paraphrased) # Add the paraphrased question to the list for the current question ID\n",
    "            elif current_qid is not None and line.startswith(\"*\"):# Check if the line starts with an asterisk, indicating a paraphrased question\n",
    "                paraphrased_map[current_qid].append(line.strip(\"* \").strip())\n",
    "            elif current_qid is not None:\n",
    "                paraphrased_map[current_qid].append(line.strip()) #If we have a current_qid and the line didn't start with \"Q...\" or an asterisk, we assume this line is also a paraphrase for the current original question.\n",
    "    return paraphrased_map\n",
    "\n",
    "# === Step 3: Create the test set and write to CSV ===\n",
    "def create_test_set_csv(qa_data, paraphrased_map, csv_path):\n",
    "    with open(csv_path, mode=\"w\", encoding=\"utf-8\", newline=\"\") as f:\n",
    "        writer = csv.writer(f) # Create a CSV writer object\n",
    "        writer.writerow([\"Number\", \"Question\", \"Answer\", \"Chunk\"])# Write the header row\n",
    "\n",
    "        for i, qa in enumerate(qa_data[:75]):#Loop through the first 75 entries in the qa_data list\n",
    "            writer.writerow([2*i+1, qa[\"question\"], qa[\"answer\"], qa[\"chunk\"]]) # Write the original question, answer, and chunk\n",
    "            para_qs = paraphrased_map.get(i+1) # Get the paraphrased questions for the current question ID. The i+1 is used because the question IDs in the paraphrased_map are 1-based.\n",
    "            if para_qs:\n",
    "                writer.writerow([2*i+2, para_qs[0], qa[\"answer\"], qa[\"chunk\"]]) # Write the first paraphrased question, answer, and chunk\n",
    "    print(f\"Test set saved to: {csv_path}\")\n",
    "\n",
    "# === Main function ===\n",
    "def main():\n",
    "    docx_path = \"Manual QA.docx\"\n",
    "    txt_path = \"paraphrased_questions.txt\"\n",
    "    output_csv = \"final_test_set.csv\"\n",
    "\n",
    "    qa_data = parse_docx(docx_path)\n",
    "    paraphrased_map = parse_paraphrases(txt_path)\n",
    "    create_test_set_csv(qa_data, paraphrased_map, output_csv)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
